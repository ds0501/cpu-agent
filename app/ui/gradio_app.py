import gradio as gr
from typing import List, Tuple
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from app.graph.app import create_agent_graph
from app.graph.state import AgentState 
from app.tools import index_pdf_file
import asyncio

# ì—ì´ì „íŠ¸ ê·¸ë˜í”„ë¥¼ í•œ ë²ˆë§Œ ì´ˆê¸°í™”í•˜ëŠ” ì „ì—­ ë³€ìˆ˜ (ì§€ì—° ì´ˆê¸°í™”)
_agent_app = None

def get_agent_app():
    """ì—ì´ì „íŠ¸ ê·¸ë˜í”„ë¥¼ ì´ˆê¸°í™”í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _agent_app
    if _agent_app is None:
        _agent_app = create_agent_graph()
    return _agent_app


# LangGraph ì‹¤í–‰ ë° ì±„íŒ… ê¸°ë¡ ê´€ë¦¬ í•¨ìˆ˜
async def run_agent(message: str, history: List[Tuple[str, str]]):
    """
    ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë°›ì•„ LangGraph Agentë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    agent_app = get_agent_app()
    chat_history = []
    # Gradio historyì˜ íŠœí”Œ ë©”ì‹œì§€ë¥¼ LangChain ë©”ì‹œì§€ ê°ì²´ë¡œ ë³€í™˜
    for item in history:
        user_msg = None
        ai_msg = None
        
        # 1. í•­ëª©ì´ íŠœí”Œ(ì´ì „ ë°©ì‹)ì¸ ê²½ìš° ì²˜ë¦¬
        if isinstance(item, tuple) and len(item) == 2:
            user_msg, ai_msg = item
            
        # 2. í•­ëª©ì´ ë”•ì…”ë„ˆë¦¬(Gradio ChatMessage)ì¸ ê²½ìš° ì²˜ë¦¬ (ì£¼ë¡œ ë°œìƒí•˜ëŠ” ë¬¸ì œ)
        elif isinstance(item, dict):
            # 'content'ê°€ ë¦¬ìŠ¤íŠ¸ì´ê³  ë”•ì…”ë„ˆë¦¬ë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if item.get('role') == 'user' and item.get('content') and isinstance(item['content'][0], dict):
                user_msg = item['content'][0].get('text')
            elif item.get('role') == 'assistant' and item.get('content') and isinstance(item['content'][0], dict):
                ai_msg = item['content'][0].get('text')
        
        # 3. íŠœí”Œë„ ë”•ì…”ë„ˆë¦¬ë„ ì•„ë‹ˆê±°ë‚˜ ìœ íš¨í•œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ê±´ë„ˆëœë‹ˆë‹¤.
        if user_msg is None and ai_msg is None:
            # ìœ íš¨í•˜ì§€ ì•Šì€ í•­ëª©ì— ëŒ€í•œ ê²½ê³  ë¡œê·¸ë¥¼ ë‚¨ê¹ë‹ˆë‹¤.
            # print(f"ê²½ê³ : Gradio history í•­ëª©ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {item}") # ì´ë¯¸ ì¶œë ¥ë˜ì—ˆìœ¼ë¯€ë¡œ ì œê±° ê°€ëŠ¥
            continue

        # 4. LangChain ë©”ì‹œì§€ ê°ì²´ ìƒì„± (user_msgì™€ ai_msg ëª¨ë‘ Noneì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
        if user_msg:
            chat_history.append(HumanMessage(content=user_msg))
        if ai_msg:
            chat_history.append(AIMessage(content=ai_msg))

    # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    chat_history.append(HumanMessage(content=message))
    
    # 2. ì´ˆê¸° State ì •ì˜
    initial_state = AgentState(
        messages=chat_history,
        lecture_index_status="READY", 
        long_term_memory_query="" 
    )

    # 3. Agent ì‹¤í–‰ (astream ì‚¬ìš©)
    current_response = ""
    tool_status_message = "" # Tool ì‹¤í–‰ ì¤‘ ë©”ì‹œì§€ ê´€ë¦¬ë¥¼ ìœ„í•œ ë³€ìˆ˜
    
    # LangGraphì˜ astreamì„ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
    async for chunk in agent_app.astream(initial_state): 
        
        # LLM ë…¸ë“œ ì²˜ë¦¬ (ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°)
        if "llm_node" in chunk:
            ai_message = chunk["llm_node"]["messages"][-1]
            
            # ìµœì¢… ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°
            if ai_message.content and not ai_message.tool_calls:
                # Tool ìƒíƒœ ë©”ì‹œì§€ë¥¼ ì œê±°í•˜ê³  ìƒˆ ì‘ë‹µì„ ì¶”ê°€
                current_response = current_response.replace(tool_status_message, "")
                current_response += ai_message.content
                yield current_response
                tool_status_message = "" # Tool ìƒíƒœ ì´ˆê¸°í™”

        # Tool ë…¸ë“œ ì²˜ë¦¬ (Tool ì‹¤í–‰ ì•Œë¦¼)
        if "tool_node" in chunk:
            # Tool ì‹¤í–‰ ì¤‘ì„ì„ ì•Œë¦¬ëŠ” ì„ì‹œ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
            if not tool_status_message:
                tool_status_message = "\n\n**... Tool ì‹¤í–‰ ì¤‘. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...**"
                if current_response and not current_response.endswith('\n\n'):
                     current_response += "\n\n"
                current_response += tool_status_message
                yield current_response

# PDF ì—…ë¡œë“œ ë° ìƒ‰ì¸ ê¸°ëŠ¥
def handle_pdf_upload(file):
    """
    PDF íŒŒì¼ì„ ë°›ì•„ RAG ìƒ‰ì¸ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    (A ì—­í• ì˜ 'index_pdf_file' í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒìœ¼ë¡œ ê°€ì •)
    """
    if file is None:
        return "PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    
    file_path = file.name
    
    # 1. A ì—­í• ì˜ RAG ìƒ‰ì¸ í•¨ìˆ˜ í˜¸ì¶œ
    try:
        # A ì—­í• ì´ êµ¬í˜„í•œ RAG ìƒ‰ì¸ í•¨ìˆ˜ (ì²­í¬, ì„ë² ë”©, Chroma DB ì €ì¥)
        index_pdf_file(file_path)
        return f"âœ… '{file_path}' íŒŒì¼ ìƒ‰ì¸ ì™„ë£Œ. ì´ì œ ê°•ì˜ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"âŒ íŒŒì¼ ìƒ‰ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

def create_gradio_interface():
    """
    Gradio ì•± ì¸í„°í˜ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    (FastAPIì— ë§ˆìš´íŠ¸í•  ë•Œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜)
    """
    
    with gr.Blocks(title="AI í•™ìŠµ ì½”ì¹˜ Agent (LangGraph + RAG)") as demo:
        gr.Markdown(
            """
            # ğŸ¯ AI í•™ìŠµ ì½”ì¹˜ / ê°•ì˜ìë£Œ RAG ì—ì´ì „íŠ¸
            LangGraph ê¸°ë°˜ ReAct êµ¬ì¡°ë¡œ ì‘ë™í•˜ëŠ” ì§€ëŠ¥í˜• í•™ìŠµ ì½”ì¹˜ì…ë‹ˆë‹¤.
            ê°•ì˜ ìë£Œ(PDF)ë¥¼ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸í•´ ë³´ì„¸ìš”!
            """
        )

        # 1. PDF ì—…ë¡œë“œ ì˜ì—­
        with gr.Row():
            pdf_file = gr.File(label="ê°•ì˜ PDF íŒŒì¼ ì—…ë¡œë“œ", file_types=[".pdf"], type="filepath")
            index_output = gr.Textbox(label="ìƒ‰ì¸ ìƒíƒœ", value="íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ RAG ìƒ‰ì¸ì´ ì‹œì‘ë©ë‹ˆë‹¤.", interactive=False)
            
            pdf_file.upload(
                fn=handle_pdf_upload,
                inputs=[pdf_file],
                outputs=[index_output]
            )
            
        gr.Markdown("---")

        # 2. ì±„íŒ… ì˜ì—­
        chatbot = gr.ChatInterface(
            fn=run_agent,
            chatbot=gr.Chatbot(height=500),
            textbox=gr.Textbox(placeholder="ê°•ì˜ ë‚´ìš© ë˜ëŠ” ì¼ë°˜ì ì¸ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...", container=False, scale=7),
            title="AI í•™ìŠµ ì½”ì¹˜ ì±„íŒ…",
            # ë¬¸ì œê°€ ë˜ëŠ” ë²„íŠ¼ ì¸ìë“¤ì€ ëª¨ë‘ ì œê±°í–ˆìŠµë‹ˆë‹¤.
        )
        
    return demo
